output_dir: finalresults/agnn_full

trainer:
    name: gnn_sparse

data:
    name: hitgraphs_sparse
    input_dir: results_larger
    n_train: 70
    n_valid: 30
    real_weight: 3
    batch_size: 2
    n_workers: 4

model:
    name: agnn
    input_dim: 3
    hidden_dim: 30
    hidden_activation: Tanh
    n_graph_iters: 8
    layer_norm: true
    loss_func: binary_cross_entropy

optimizer:
    name: Adam
    learning_rate: 0.005
    weight_decay: 1.e-4
    lr_decay_schedule:
        - {start_epoch: 64, end_epoch: 128, factor: 0.1}

training:
    n_total_epochs: 128

